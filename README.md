# Camera-based Hand Tracking and Reconstruction for Intuitive Interaction in Virtual Environment

A real-time hand tracking system using a standard webcam and MediaPipe for intuitive gesture-based interaction in 3D Unity environments — no expensive VR/AR hardware required!

## 📌 Introduction

This project focuses on developing a **camera-based hand tracking system** that enables natural hand gesture interactions within a virtual 3D environment. Using **OpenCV**, **MediaPipe**, and **Unity**, we provide a **cost-effective** and **intuitive** alternative to traditional VR/AR setups.

---

## 🎥 Demo Video

[YouTube Demo](https://youtu.be/hwRFSPdlC5Q)

---

## 🔍 Overview

- 🎥 **OpenCV** captures real-time video from a webcam.
- ✋ **MediaPipe** extracts 21 2D hand landmarks per frame.
- 🧠 Post-processing infers 3D hand positions and gestures.
- 🔄 3D coordinates are streamed into a **Unity** scene.
- 🖐️ A virtual hand mimics user movement for immersive interaction.

> Users can **grab, rotate, zoom, and move objects** with just their hands.

<img src="readme image/hand to 3d pic.png" alt="Landmark Detection and Reconstruction in Unity" height = 450/>

---

## 🌌 Demo: Solar System Interaction

As a proof-of-concept, we created a mini **solar system** in Unity:

- 🪐 Touch planets to reveal educational info.
- 🌍 Grab and move Earth to alter orbit.
- 🎮 Rotate the environment with hand gestures.

> This demo showcases the potential for **interactive educational games and programs**.
<p>
  <a href="https://youtu.be/hwRFSPdlC5Q"></a>
<img src="readme image/unity solar system.png" alt="Solar System Interaction Demo" height = 450/>
</p>
Click the above image to watch the demo.

---

## 🎯 Key Features

- **📸 Accessibility**: Works with a basic webcam—no VR headset needed!
- **🖱️ Intuitive Gestures**: Interact without a mouse or controller.
- **🎓 Education-Ready**: Great for learning physics and space science.
- **🕹️ Versatile**: Use in games, virtual meetings, or simulations.

---

## 🚀 Applications

- **Education**: Visualize complex topics through interactive learning.
- **Accessibility**: Provide alternative input for users with mobility challenges.
- **Remote Collaboration**: Enable expressive gestures in virtual meetings.
- **Gaming**: Build immersive hand-controlled gameplay mechanics.

---

## ✅ Conclusion

This project demonstrates the potential of camera-based hand tracking for enhancing user interaction in virtual environments. By using affordable and readily available technology, we are able to create intuitive, immersive, and educational experiences that are both engaging and inclusive. The approach opens the door to a wide range of applications, from interactive learning tools to accessible gaming and collaboration platforms, all without the need for expensive hardware. Our work lays the foundation for a more interactive and widely accessible digital future.

---

## 📷 Built With

- [Python](https://www.python.org/)
- [OpenCV](https://opencv.org/)
- [MediaPipe](https://mediapipe.dev/)
- [Unity](https://unity.com/)

---

## 👬 Team

<a href="https://github.com/sunjinwoo1298/camera-based-hand-tracking-and-reconstruction-for-intuitive-interaction-in-virtual-environment/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=sunjinwoo1298/camera-based-hand-tracking-and-reconstruction-for-intuitive-interaction-in-virtual-environment" />
</a>
